{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Analysis Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Common Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import paper_analysis_utils as pau\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Path to the experiments provided in SnS_experiments on Zenodo\n",
    "SNS_METADATA_PATH = \"path/to/SnS_multiexp_dirs.json\" \n",
    "# Full path to the distance_params.json in demo\n",
    "DIST_PARAMS_PATH = 'path/to/demo/distance_params.json' \n",
    "# Full path to the multiNets_accuracy data provided on Zenodo,\n",
    "# pattern of the folder names to mathc (e.g. 'SnS_nats_*_115')\n",
    "MULTINET_ACCURACY_SEARCH_PATTERN = os.path.join('path/to/accuracy/experiments/in/other/networks', \"folder name to pattern match\", \"accuracy.json\") \n",
    "# Full path to the multinet_params.json in demo\n",
    "MULTINET_DIST_PARAMS_SOURCE = 'path/to/demo/multinet_params.json' \n",
    "# Full path to human accuracy data provided on Zenodo\n",
    "HUMAN_DATA_PATH = 'path/to/humanAcc.csv' # For MultiNet Correlation\n",
    "\n",
    "BASE_OUTPUT_DIR = \"./paper_analysis_outputs\"\n",
    "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ---Data Loading ---\n",
    "try:\n",
    "    experiments_metadata = pau.SnS_metadata.from_json(SNS_METADATA_PATH, recalculate=False)\n",
    "    print(f\"Successfully loaded SnS_metadata from {SNS_METADATA_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SnS_metadata: {e}. Some analyses might fail.\")\n",
    "    experiments_metadata = None\n",
    "\n",
    "try:\n",
    "    prms_dist = pau.read_json(DIST_PARAMS_PATH)\n",
    "    print(f\"Successfully loaded distance parameters from {DIST_PARAMS_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading distance parameters: {e}. Distance analysis might fail.\")\n",
    "    prms_dist = None\n",
    "\n",
    "# Initialize a general-purpose generator (e.g., fc7)\n",
    "try:\n",
    "    # Using WEIGHTS from pau, which might be a placeholder if experiment.utils.args is not found\n",
    "    generator_fc7 = pau.DeePSiMGenerator(root=str(pau.WEIGHTS), variant='fc7').to(DEVICE)\n",
    "    print(\"Initialized DeePSiMGenerator (fc7 variant).\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing DeePSiMGenerator (fc7): {e}\")\n",
    "    generator_fc7 = None\n",
    "\n",
    "# Initialize a reference TorchNetworkSubject for SVC (standard resnet50, '00_input_01')\n",
    "rec_ly_svc = '00_input_01'\n",
    "try:\n",
    "    probe_svc = pau.RecordingProbe(target={rec_ly_svc: []})\n",
    "    # Using torch_load from pau (pxdream.utils.torch_net_load_functs)\n",
    "    repr_net_svc_resnet50_vanilla = pau.TorchNetworkSubject(\n",
    "        record_probe=probe_svc, \n",
    "        network_name='resnet50', \n",
    "        t_net_loading=pau.torch_load, \n",
    "        custom_weights_path=''\n",
    "    ).eval().to(DEVICE)\n",
    "    print(\"Initialized TorchNetworkSubject for SVC (ResNet50 vanilla, '00_input_01').\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing TorchNetworkSubject for SVC: {e}\")\n",
    "    repr_net_svc_resnet50_vanilla = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Centroid Plot + Activation Percentiles Boxplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  snslib.metaexperiment.metaexp_functs import nat_percentiles\n",
    "import importlib\n",
    "import  snslib.metaexperiment.plots\n",
    "importlib.reload( snslib.metaexperiment.plots)\n",
    "from  snslib.metaexperiment.plots import SnS_scatterplot\n",
    "\n",
    "experiments_metadata.apply_analysis(queries=[['resnet50', '56_linear_01','robust_l2', '00_input_01', '500', 'invariance 2.0'],['resnet50', '56_linear_01','robust_l2', '00_input_01', '500', 'adversarial 1.0']],\n",
    "    callables=[nat_percentiles, SnS_scatterplot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiments_metadata:\n",
    "    # Define experiment queries \n",
    "    exp_std_inv_pix = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','vanilla', '00_input_01', '500', 'invariance 2.0']])\n",
    "    exp_std_inv_25  = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','vanilla', '26_conv_25', '500', 'invariance 2.0']])\n",
    "    exp_std_inv_51  = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','vanilla', '52_conv_51', '500', 'invariance 2.0']])\n",
    "    exp_std_adv_pix = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','vanilla', '00_input_01', '500', 'adversarial 1.0']])\n",
    "\n",
    "    exp_r_inv_pix  = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','robust_l2', '00_input_01', '500', 'invariance 2.0']])\n",
    "    exp_r_inv_25    = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','robust_l2', '26_conv_25', '500', 'invariance 2.0']])\n",
    "    exp_r_inv_51    = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','robust_l2', '52_conv_51', '500', 'invariance 2.0']])\n",
    "    exp_r_adv_pix   = experiments_metadata.get_experiments(queries=[['resnet50', '56_linear_01','robust_l2', '00_input_01', '500', 'adversarial 1.0']])\n",
    "\n",
    "    # Calculate activation percentiles \n",
    "    print(\"Calculating activation percentiles...\")\n",
    "    nat_stats_std_inv_pix = pau.calculate_activation_percentiles(exps=exp_std_inv_pix)\n",
    "    nat_stats_r_inv_pix   = pau.calculate_activation_percentiles(exps=exp_r_inv_pix)\n",
    "    nat_stats_std_inv_25  = pau.calculate_activation_percentiles(exps=exp_std_inv_25)\n",
    "    nat_stats_r_inv_25    = pau.calculate_activation_percentiles(exps=exp_r_inv_25)\n",
    "    nat_stats_std_inv_51  = pau.calculate_activation_percentiles(exps=exp_std_inv_51)\n",
    "    nat_stats_r_inv_51    = pau.calculate_activation_percentiles(exps=exp_r_inv_51)\n",
    "    nat_stats_adv_std     = pau.calculate_activation_percentiles(exps=exp_std_adv_pix)\n",
    "    nat_stats_adv_rob     = pau.calculate_activation_percentiles(exps=exp_r_adv_pix)\n",
    "    \n",
    "\n",
    "    # Generate the boxplot\n",
    "    print(\"\\nGenerating Plot 1 (Standard Invariance and Adversarial)...\")\n",
    "    sns_experiments_plot1 = [\n",
    "        # Order matters for visual grouping \n",
    "        (\"Adv Pixel space\", nat_stats_adv_std, nat_stats_adv_rob),\n",
    "        (\"Inv Pixel space\", nat_stats_std_inv_pix, nat_stats_r_inv_pix),\n",
    "        (\"Inv Layer3_conv1\", nat_stats_std_inv_25, nat_stats_r_inv_25),\n",
    "        (\"Inv Layer4_conv7\", nat_stats_std_inv_51, nat_stats_r_inv_51)\n",
    "    ]\n",
    "    \n",
    "    pau.plot_activation_percentiles_boxplot(\n",
    "        general_stats_std=nat_stats_std_inv_pix, # For 'Same cat.', 'Other cats.'\n",
    "        general_stats_rob=nat_stats_r_inv_pix,\n",
    "        sns_experiment_data=sns_experiments_plot1,\n",
    "        save_dir=os.path.join(BASE_OUTPUT_DIR, \"activation_boxplot_outputs\"),\n",
    "        filename=\"activation_percentiles_plot1_inv_adv.png\"\n",
    "    )\n",
    "else:\n",
    "    print(\"SnS_metadata not loaded. Skipping Activation Percentiles Boxplot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_convergence_niter={}\n",
    "median_nat_perc = {}\n",
    "for exp in [exp_std_inv_pix,exp_std_inv_25,exp_std_inv_51,exp_std_adv_pix,exp_r_inv_pix,exp_r_inv_25,exp_r_inv_51,exp_r_adv_pix]:\n",
    "    exp_name= list(exp.keys())[0]\n",
    "    exp_df = exp[exp_name]['df']\n",
    "    percent_convergence_niter[exp_name] = (exp_df['nat_stat_early_stopping_p1_n_it'].isna().sum()/exp_df['nat_stat_early_stopping_p1_n_it'].shape[-1])\n",
    "    median_nat_perc[exp_name] = exp_df['nat_percentiles'].median()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_nat_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence rate for target units in readout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_convergence_niter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence rate for target units in mid and high levels of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_std_mid_trg25 = experiments_metadata.get_experiments(queries=[['resnet50', '26_conv_25','vanilla', '00_input_01', '500', 'invariance 2.0']])\n",
    "exp_std_high_trg51 = experiments_metadata.get_experiments(queries=[['resnet50', '52_conv_51','vanilla', '00_input_01', '500', 'invariance 2.0']])\n",
    "\n",
    "\n",
    "exp_r_mid_trg25 = experiments_metadata.get_experiments(queries=[['resnet50', '26_conv_25','robust_l2', '00_input_01', '500', 'invariance 2.0']])\n",
    "exp_r_high_trg51 = experiments_metadata.get_experiments(queries=[['resnet50', '52_conv_51','robust_l2', '00_input_01', '500', 'invariance 2.0']])\n",
    "\n",
    "\n",
    "percent_convergence_niter_diffTRG={}\n",
    "median_nat_perc_diffTRG = {}\n",
    "for exp in [exp_std_mid_trg25,exp_std_high_trg51,exp_r_mid_trg25,exp_r_high_trg51]:\n",
    "    exp_name= list(exp.keys())[0]\n",
    "    exp_df = exp[exp_name]['df']\n",
    "    percent_convergence_niter_diffTRG[exp_name] = 1-(exp_df['nat_stat_early_stopping_p1_n_it'].isna().sum()/exp_df['nat_stat_early_stopping_p1_n_it'].shape[-1])\n",
    "    \n",
    "nat_stats_std_mid_trg25 = pau.calculate_activation_percentiles(exps=exp_std_mid_trg25)\n",
    "nat_stats_r_mid_trg25   = pau.calculate_activation_percentiles(exps=exp_r_mid_trg25)\n",
    "nat_stats_std_high_trg51  = pau.calculate_activation_percentiles(exps=exp_std_high_trg51)\n",
    "nat_stats_r_high_trg51    = pau.calculate_activation_percentiles(exps=exp_r_high_trg51)\n",
    "\n",
    "if 'nat_stats_std_mid_trg25' in locals() and 'nat_stats_std_high_trg51' in locals():\n",
    "    sns_experiments_plot2 = [\n",
    "        (\"Mid Level Targets \", nat_stats_std_mid_trg25, nat_stats_r_mid_trg25),\n",
    "        (\"High Level Targets \", nat_stats_std_high_trg51, nat_stats_r_high_trg51)\n",
    "        \n",
    "    ]\n",
    "\n",
    "   \n",
    "    pau.plot_activation_percentiles_boxplot(\n",
    "        general_stats_std=nat_stats_std_mid_trg25, \n",
    "        general_stats_rob=nat_stats_r_mid_trg25,\n",
    "        sns_experiment_data=sns_experiments_plot2,\n",
    "        save_dir=os.path.join(BASE_OUTPUT_DIR, \"activation_boxplot_outputs\"),\n",
    "        filename=\"activation_percentiles_plot2_mid_high.png\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Data for Plot 2 (Mid/High Target) not available. Skipping.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_convergence_niter_diffTRG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVC Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiments_metadata and generator_fc7 and repr_net_svc_resnet50_vanilla:\n",
    "    print(\"Starting SVC Analysis...\")\n",
    "    # Get experiment data for 'vanilla' and 'robust_l2'\n",
    "    queries_vanilla_svc = [\n",
    "        ['resnet50', '56_linear_01','vanilla', '00_input_01', '500', 'invariance 2.0'],\n",
    "        ['resnet50', '56_linear_01','vanilla', '26_conv_25', '500', 'invariance 2.0'],\n",
    "        ['resnet50', '56_linear_01','vanilla', '52_conv_51', '500', 'invariance 2.0']\n",
    "    ]\n",
    "    exp_vanilla_svc = experiments_metadata.get_experiments(queries=queries_vanilla_svc)\n",
    "\n",
    "    queries_robust_l2_svc = [\n",
    "        ['resnet50', '56_linear_01','robust_l2', '00_input_01', '500', 'invariance 2.0'],\n",
    "        ['resnet50', '56_linear_01','robust_l2', '26_conv_25', '500', 'invariance 2.0'],\n",
    "        ['resnet50', '56_linear_01','robust_l2', '52_conv_51', '500', 'invariance 2.0']\n",
    "    ]\n",
    "    exp_robust_l2_svc = experiments_metadata.get_experiments(queries=queries_robust_l2_svc)\n",
    "    \n",
    "    # Process data for 'vanilla' SVC\n",
    "    print(\"\\nProcessing 'vanilla' experiments for SVC...\")\n",
    "    reprs_vanilla = pau.process_experiment_data_for_svc(\n",
    "        exp_vanilla_svc, p1='end_p1_idxs', rec_ly=rec_ly_svc, \n",
    "        generator=generator_fc7, repr_net=repr_net_svc_resnet50_vanilla, DEVICE=DEVICE\n",
    "    )\n",
    "    final_result_vanilla = pau.unify_representations(reprs_vanilla)\n",
    "    \n",
    "    npcs_values_svc = [2, 10, 25, 50, 100]\n",
    "    van_results_svc = []\n",
    "    if final_result_vanilla and rec_ly_svc in final_result_vanilla[0] and final_result_vanilla[0][rec_ly_svc].size > 0:\n",
    "        van_results_svc = pau.calculate_classwise_scores_svc(\n",
    "            final_result_vanilla[0][rec_ly_svc], \n",
    "            np.array(final_result_vanilla[1]), \n",
    "            npcs_values_svc\n",
    "        )\n",
    "        print(\"Completed 'vanilla' SVC processing.\")\n",
    "    else:\n",
    "        print(\"Warning: No data for 'vanilla' SVC after processing. Skipping score calculation.\")\n",
    "\n",
    "    # Process data for 'robust_l2' SVC\n",
    "    print(\"\\nProcessing 'robust_l2' experiments for SVC...\")\n",
    "    reprs_robust = pau.process_experiment_data_for_svc(\n",
    "        exp_robust_l2_svc, p1='end_p1_idxs', rec_ly=rec_ly_svc, \n",
    "        generator=generator_fc7, repr_net=repr_net_svc_resnet50_vanilla, DEVICE=DEVICE # Using same standard ResNet50 for representation\n",
    "    )\n",
    "    final_result_robust = pau.unify_representations(reprs_robust)\n",
    "    \n",
    "    rob_results_svc = []\n",
    "    if final_result_robust and rec_ly_svc in final_result_robust[0] and final_result_robust[0][rec_ly_svc].size > 0:\n",
    "        rob_results_svc = pau.calculate_classwise_scores_svc(\n",
    "            final_result_robust[0][rec_ly_svc], \n",
    "            np.array(final_result_robust[1]), \n",
    "            npcs_values_svc\n",
    "        )\n",
    "        print(\"Completed 'robust_l2' SVC processing.\")\n",
    "    else:\n",
    "        print(\"Warning: No data for 'robust_l2' SVC after processing. Skipping score calculation.\")\n",
    "\n",
    "    # Plot SVC results\n",
    "    if van_results_svc or rob_results_svc: # Check if there are any results to plot\n",
    "        print(\"\\nPlotting SVC results...\")\n",
    "        display_names_map_svc = {\n",
    "            '00_input_01': 'Pixel Space',\n",
    "            '26_conv_25':  'Layer3_conv1',\n",
    "            '52_conv_51':  'Layer4_conv7'\n",
    "        }\n",
    "        # Use keys from one of the experiment dicts for layer labels in the plot legend\n",
    "        # The specific choice (vanilla or robust) for keys mainly affects label generation if formats differ.\n",
    "        # Assuming consistent formatting, either should work. Original used the last one (robust).\n",
    "        exp_keys_for_plot = list(exp_robust_l2_svc.keys()) if exp_robust_l2_svc else list(exp_vanilla_svc.keys())\n",
    "        \n",
    "        pau.plot_svc_accuracy(\n",
    "            van_results_svc, rob_results_svc, \n",
    "            exp_keys_source=exp_keys_for_plot, \n",
    "            display_names_map=display_names_map_svc, \n",
    "            save_dir=os.path.join(BASE_OUTPUT_DIR, \"svc_analysis_outputs\")\n",
    "        )\n",
    "    else:\n",
    "        print(\"No results to plot for SVC analysis.\")\n",
    "else:\n",
    "    print(\"SnS_metadata, generator, or SVC reference network not loaded. Skipping SVC Analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distance Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prms_dist and SNS_METADATA_PATH: # Ensure prms_dist is loaded\n",
    "    print(\"Starting Distance Analysis...\")\n",
    "    da_results = pau.run_full_distance_analysis(\n",
    "        prms_dist,\n",
    "        SNS_METADATA_PATH, # Pass path, SnS_metadata will be loaded inside run_full_distance_analysis\n",
    "        DEVICE,\n",
    "        BASE_OUTPUT_DIR\n",
    "    )\n",
    "    print(\"\\nDistance Analysis complete.\")\n",
    "    print(f\"Results saved in: {da_results['analysis_dir']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Network Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Multi-Network Accuracy Analysis...\")\n",
    "mn_df, mn_df_orig, mn_color_map, mn_ordered_labels = pau.load_and_process_multinet_accuracies(\n",
    "    search_pattern=MULTINET_ACCURACY_SEARCH_PATTERN,\n",
    "    dist_params_plotting_source_path=MULTINET_DIST_PARAMS_SOURCE\n",
    ")\n",
    "\n",
    "if not mn_df.empty:\n",
    "    print(\"\\nPlotting multi-network accuracy trends...\")\n",
    "    pau.plot_multinet_accuracy_trends(\n",
    "        mn_df, mn_ordered_labels, mn_color_map,\n",
    "        save_dir=os.path.join(BASE_OUTPUT_DIR, \"multinet_analysis_outputs\")\n",
    "    )\n",
    "\n",
    "    print(\"\\nPerforming correlation analysis with human data...\")\n",
    "    mn_correlations, mn_p_values = pau.perform_correlation_analysis_with_human(\n",
    "        human_data_path=HUMAN_DATA_PATH,\n",
    "        model_df_orig=mn_df_orig,\n",
    "        color_map=mn_color_map,\n",
    "        save_dir=os.path.join(BASE_OUTPUT_DIR, \"multinet_analysis_outputs\")\n",
    "    )\n",
    "    if mn_correlations:\n",
    "        print(\"\\nTop 3 Model Correlations with Human Data:\")\n",
    "        for i, (model, r_val) in enumerate(mn_correlations.items()):\n",
    "            if i < 3:\n",
    "                print(f\"  {model}: r = {r_val:.3f}, p = {mn_p_values[model]:.3g}\")\n",
    "            else:\n",
    "                break\n",
    "else:\n",
    "    print(\"No data loaded for multi-network analysis. Skipping plots and correlations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
